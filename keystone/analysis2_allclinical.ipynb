{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ENROLLEES = pd.read_csv('Comma Delimited Data/enrollees.csv').drop(['VERSION'],axis=1)\n",
    "ENROLLEES = ENROLLEES[['ID','P02HISP','P02SEX', 'P02RACE']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Target Data (outcomes99.csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = pd.read_csv('Comma Delimited Data/outcomes99.csv').drop(['version'],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Grouping features names by meaning..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tRPCF = [i for i in dt.columns if i[-4:] =='RPCF']   # Knee and hip replacement status during follow-up\n",
    "tBLRP = [i for i in dt.columns if i[-4:] =='BLRP']   # Baseline knee or hip replacements\n",
    "tRPSN = [i for i in dt.columns if i[-4:] =='RPSN']   # Knee or hip replacement seen on follow-up OAI x-ray.\n",
    "tDAYS = [i for i in dt.columns if i[-4:] =='DAYS']   # Closest OAI contact prior to and after replacement\n",
    "tVSPR = [i for i in dt.columns if i[-4:] =='VSPR']   # Closest OAI contact prior to replacement\n",
    "tXRPR = [i for i in dt.columns if i[-4:] =='XRPR']   # Closest OAI visit with x-ray prior to replacement\n",
    "tXRAF = [i for i in dt.columns if i[-4:] =='XRAF']   # Closest OAI visit with x-ray after the replacement\n",
    "\n",
    "tVSAF = [i for i in dt.columns if i[-4:] =='VSAF']   # Closest OAI contact after the replacement\n",
    "tDATE = [i for i in dt.columns if i[-4:] =='DATE']   # Date of a replacement\n",
    "tTLPR = [i for i in dt.columns if i[-4:] =='TLPR']   # Total or Partial replacement indication\n",
    "tTPPR = [i for i in dt.columns if i[-4:] =='TPPR']   # Type of Partial replacement indication\n",
    "tPODX = [i for i in dt.columns if i[-4:] =='PODX']   # Primary pre-operative diagnosis\n",
    "tDEATH = [i for i in dt.columns if i[-4:] =='EDDCF'] # Death columns\n",
    "\n",
    "DT_outcome = dt[['id'] + tRPCF + tBLRP + tPODX + tVSPR + tDEATH]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>V99ERKRPCF</th>\n",
       "      <th>V99ELKRPCF</th>\n",
       "      <th>V99ERHRPCF</th>\n",
       "      <th>V99ELHRPCF</th>\n",
       "      <th>V99ERKBLRP</th>\n",
       "      <th>V99ELKBLRP</th>\n",
       "      <th>V99ERHBLRP</th>\n",
       "      <th>V99ELHBLRP</th>\n",
       "      <th>V99ERKPODX</th>\n",
       "      <th>V99ELKPODX</th>\n",
       "      <th>V99ERHPODX</th>\n",
       "      <th>V99ELHPODX</th>\n",
       "      <th>V99ERKVSPR</th>\n",
       "      <th>V99ELKVSPR</th>\n",
       "      <th>V99ERHVSPR</th>\n",
       "      <th>V99ELHVSPR</th>\n",
       "      <th>V99EDDVSPR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9000099</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9000296</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9000622</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9000798</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9001104</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id  V99ERKRPCF  V99ELKRPCF  V99ERHRPCF  V99ELHRPCF  V99ERKBLRP  \\\n",
       "0  9000099         NaN         NaN         NaN         NaN         NaN   \n",
       "1  9000296         NaN         NaN         NaN         NaN         NaN   \n",
       "2  9000622         NaN         NaN         NaN         NaN         0.0   \n",
       "3  9000798         NaN         NaN         NaN         NaN         NaN   \n",
       "4  9001104         NaN         NaN         NaN         3.0         0.0   \n",
       "\n",
       "   V99ELKBLRP  V99ERHBLRP  V99ELHBLRP  V99ERKPODX  V99ELKPODX  V99ERHPODX  \\\n",
       "0         NaN         NaN         NaN         NaN         NaN         NaN   \n",
       "1         NaN         NaN         NaN         NaN         NaN         NaN   \n",
       "2         0.0         0.0         0.0         NaN         NaN         NaN   \n",
       "3         NaN         NaN         NaN         NaN         NaN         NaN   \n",
       "4         0.0         0.0         0.0         NaN         NaN         NaN   \n",
       "\n",
       "   V99ELHPODX  V99ERKVSPR  V99ELKVSPR  V99ERHVSPR  V99ELHVSPR  V99EDDVSPR  \n",
       "0         NaN         NaN         NaN         NaN         NaN         NaN  \n",
       "1         NaN         NaN         NaN         NaN         NaN         NaN  \n",
       "2         NaN         NaN         NaN         NaN         NaN         1.0  \n",
       "3         NaN         NaN         NaN         NaN         NaN         NaN  \n",
       "4         4.0         NaN         NaN         NaN         3.0         NaN  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DT_outcome.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Grouping features names by affected joint ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>V99ELHRPCF</th>\n",
       "      <th>V99ELHBLRP</th>\n",
       "      <th>V99ELHPODX</th>\n",
       "      <th>V99ELHVSPR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9000099</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9000296</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9000622</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9000798</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9001104</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id  V99ELHRPCF  V99ELHBLRP  V99ELHPODX  V99ELHVSPR\n",
       "0  9000099         NaN         NaN         NaN         NaN\n",
       "1  9000296         NaN         NaN         NaN         NaN\n",
       "2  9000622         NaN         0.0         NaN         NaN\n",
       "3  9000798         NaN         NaN         NaN         NaN\n",
       "4  9001104         3.0         0.0         4.0         3.0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tELK = [i for i in DT_outcome.columns if i[0:6] =='V99ELK']  # Left Knee Columns\n",
    "tERK = [i for i in DT_outcome.columns if i[0:6] =='V99ERK']  # Right Knee Columns\n",
    "tELH = [i for i in DT_outcome.columns if i[0:6] =='V99ELH']  # Left Hip Columns\n",
    "tERH = [i for i in DT_outcome.columns if i[0:6] =='V99ELH']  # Right Hip Columns\n",
    "DT_outcome[['id'] + tERH].head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>V99ERKRPCF</th>\n",
       "      <th>V99ELKRPCF</th>\n",
       "      <th>V99ERHRPCF</th>\n",
       "      <th>V99ELHRPCF</th>\n",
       "      <th>V99ERKBLRP</th>\n",
       "      <th>V99ELKBLRP</th>\n",
       "      <th>V99ERHBLRP</th>\n",
       "      <th>V99ELHBLRP</th>\n",
       "      <th>V99ERKPODX</th>\n",
       "      <th>V99ELKPODX</th>\n",
       "      <th>V99ERHPODX</th>\n",
       "      <th>V99ELHPODX</th>\n",
       "      <th>V99ERKVSPR</th>\n",
       "      <th>V99ELKVSPR</th>\n",
       "      <th>V99ERHVSPR</th>\n",
       "      <th>V99ELHVSPR</th>\n",
       "      <th>V99EDDVSPR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>4.796000e+03</td>\n",
       "      <td>4796.000000</td>\n",
       "      <td>4796.000000</td>\n",
       "      <td>4796.000000</td>\n",
       "      <td>4796.000000</td>\n",
       "      <td>4796.000000</td>\n",
       "      <td>4796.000000</td>\n",
       "      <td>4796.000000</td>\n",
       "      <td>4796.000000</td>\n",
       "      <td>4796.000000</td>\n",
       "      <td>4796.000000</td>\n",
       "      <td>4796.000000</td>\n",
       "      <td>4796.000000</td>\n",
       "      <td>4796.000000</td>\n",
       "      <td>4796.000000</td>\n",
       "      <td>4796.000000</td>\n",
       "      <td>4796.000000</td>\n",
       "      <td>4796.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>9.513826e+06</td>\n",
       "      <td>0.169725</td>\n",
       "      <td>0.167431</td>\n",
       "      <td>0.072977</td>\n",
       "      <td>0.067973</td>\n",
       "      <td>0.007923</td>\n",
       "      <td>0.005213</td>\n",
       "      <td>0.006047</td>\n",
       "      <td>0.004379</td>\n",
       "      <td>0.065680</td>\n",
       "      <td>0.071309</td>\n",
       "      <td>0.031902</td>\n",
       "      <td>0.035029</td>\n",
       "      <td>0.352585</td>\n",
       "      <td>0.335488</td>\n",
       "      <td>0.139491</td>\n",
       "      <td>0.134696</td>\n",
       "      <td>0.414721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.794781e+05</td>\n",
       "      <td>0.690747</td>\n",
       "      <td>0.686311</td>\n",
       "      <td>0.459963</td>\n",
       "      <td>0.442252</td>\n",
       "      <td>0.088669</td>\n",
       "      <td>0.072018</td>\n",
       "      <td>0.077533</td>\n",
       "      <td>0.066033</td>\n",
       "      <td>0.333187</td>\n",
       "      <td>0.408362</td>\n",
       "      <td>0.263180</td>\n",
       "      <td>0.313783</td>\n",
       "      <td>1.600233</td>\n",
       "      <td>1.534531</td>\n",
       "      <td>1.006929</td>\n",
       "      <td>0.995190</td>\n",
       "      <td>1.813524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>9.000099e+06</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>9.283430e+06</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>9.522042e+06</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>9.747572e+06</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>9.999878e+06</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>12.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id   V99ERKRPCF   V99ELKRPCF   V99ERHRPCF   V99ELHRPCF  \\\n",
       "count  4.796000e+03  4796.000000  4796.000000  4796.000000  4796.000000   \n",
       "mean   9.513826e+06     0.169725     0.167431     0.072977     0.067973   \n",
       "std    2.794781e+05     0.690747     0.686311     0.459963     0.442252   \n",
       "min    9.000099e+06     0.000000     0.000000     0.000000     0.000000   \n",
       "25%    9.283430e+06     0.000000     0.000000     0.000000     0.000000   \n",
       "50%    9.522042e+06     0.000000     0.000000     0.000000     0.000000   \n",
       "75%    9.747572e+06     0.000000     0.000000     0.000000     0.000000   \n",
       "max    9.999878e+06     3.000000     3.000000     3.000000     3.000000   \n",
       "\n",
       "        V99ERKBLRP   V99ELKBLRP   V99ERHBLRP   V99ELHBLRP   V99ERKPODX  \\\n",
       "count  4796.000000  4796.000000  4796.000000  4796.000000  4796.000000   \n",
       "mean      0.007923     0.005213     0.006047     0.004379     0.065680   \n",
       "std       0.088669     0.072018     0.077533     0.066033     0.333187   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "50%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "75%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "max       1.000000     1.000000     1.000000     1.000000     7.000000   \n",
       "\n",
       "        V99ELKPODX   V99ERHPODX   V99ELHPODX   V99ERKVSPR   V99ELKVSPR  \\\n",
       "count  4796.000000  4796.000000  4796.000000  4796.000000  4796.000000   \n",
       "mean      0.071309     0.031902     0.035029     0.352585     0.335488   \n",
       "std       0.408362     0.263180     0.313783     1.600233     1.534531   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "50%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "75%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "max       7.000000     8.000000     8.000000    10.000000    10.000000   \n",
       "\n",
       "        V99ERHVSPR   V99ELHVSPR   V99EDDVSPR  \n",
       "count  4796.000000  4796.000000  4796.000000  \n",
       "mean      0.139491     0.134696     0.414721  \n",
       "std       1.006929     0.995190     1.813524  \n",
       "min       0.000000     0.000000     0.000000  \n",
       "25%       0.000000     0.000000     0.000000  \n",
       "50%       0.000000     0.000000     0.000000  \n",
       "75%       0.000000     0.000000     0.000000  \n",
       "max      10.000000    10.000000    12.000000  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets = DT_outcome.fillna(0)\n",
    "targets.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AllClinicalDataset\n",
    "\n",
    "Reading the data for the joint dataset...\n",
    "\n",
    "Here, we are trying to consider only the __last visit__, prior to a replacement. We're trying to catch information that refers to a condition before the surgery.\n",
    "\n",
    "So:\n",
    "1. Reading datasets from files. Dropping some columns we won't use\n",
    "2. Renaming columns, changing.. VxxKPNL12, VxxKPNLEVY to... KPNL12, KPNLEVY, etc..   and refering the visit number in a separated column, named 'visit'. (So we can compare variable between the visits)\n",
    "3. Joining with the information of last visit prior to a replacement.  (this generates a dataset that have one line per visit... per each ID)\n",
    "4. Keeping just the last visit (-1) prior to replacement, or a specific visit, for each ID."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt0 = pd.read_csv('Comma Delimited Data/allclinical01.csv').drop(['VERSION'],axis=1)\n",
    "dt1 = pd.read_csv('Comma Delimited Data/allclinical02.csv').drop(['VERSION'],axis=1) \n",
    "dt2 = pd.read_csv('Comma Delimited Data/allclinical03.csv').drop(['VERSION'],axis=1)\n",
    "dt3 = pd.read_csv('Comma Delimited Data/allclinical04.csv').drop(['VERSION'],axis=1) \n",
    "dt4 = pd.read_csv('Comma Delimited Data/allclinical05.csv').drop(['VERSION'],axis=1) \n",
    "dt5 = pd.read_csv('Comma Delimited Data/allclinical06.csv').drop(['VERSION'],axis=1) \n",
    "dt6 = pd.read_csv('Comma Delimited Data/allclinical07.csv').drop(['VERSION'],axis=1) \n",
    "dt7 = pd.read_csv('Comma Delimited Data/allclinical08.csv').drop(['VERSION'],axis=1) \n",
    "dt8 = pd.read_csv('Comma Delimited Data/allclinical09.csv').drop(['VERSION'],axis=1) \n",
    "dt9 = pd.read_csv('Comma Delimited Data/allclinical10.csv').drop(['VERSION'],axis=1) \n",
    "dt10 = pd.read_csv('Comma Delimited Data/allclinical11.csv').drop(['VERSION'],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Renaming columns (removing Vxx to enable direct comparison between visits)\n",
    "\n",
    "the visit number information is kept in the 'visit' column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "dts = [dt0,dt1,dt2,dt3,dt4,dt5,dt6,dt7,dt8,dt9,dt10]\n",
    "for j in range(len(dts)):\n",
    "    d = dts[j]\n",
    "    col = list(d.columns)\n",
    "    for i in range(1,len(col)):\n",
    "        txtcol = col[i]\n",
    "        col[i] = txtcol[3:]\n",
    "    d.columns=col\n",
    "    d['visit'] = j  \n",
    "ALLDATA = pd.concat(dts,sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>BLDRAW2</th>\n",
       "      <th>ILLPWK2</th>\n",
       "      <th>MULTST2</th>\n",
       "      <th>URINOB1</th>\n",
       "      <th>PLAQHR1</th>\n",
       "      <th>BLUPMN2</th>\n",
       "      <th>HOURSP2</th>\n",
       "      <th>VCOLL2</th>\n",
       "      <th>ILLPWK1</th>\n",
       "      <th>...</th>\n",
       "      <th>ACT37A</th>\n",
       "      <th>ACT37B</th>\n",
       "      <th>ACT37C</th>\n",
       "      <th>ACT37D</th>\n",
       "      <th>ACTNAA</th>\n",
       "      <th>ACTNAB</th>\n",
       "      <th>ACTNAC</th>\n",
       "      <th>ACTNAD</th>\n",
       "      <th>prior_visit</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9000099</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>33600.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.0</td>\n",
       "      <td>9000099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9000099</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>27300.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.0</td>\n",
       "      <td>9000099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9000099</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>53700.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.0</td>\n",
       "      <td>9000099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9000099</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>29700.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.0</td>\n",
       "      <td>9000099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9000099</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>27600.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.0</td>\n",
       "      <td>9000099</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1426 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        ID  BLDRAW2  ILLPWK2  MULTST2  URINOB1  PLAQHR1  BLUPMN2  HOURSP2  \\\n",
       "0  9000099      NaN      NaN      NaN      1.0  33600.0      NaN      NaN   \n",
       "1  9000099      NaN      NaN      NaN      1.0  27300.0      NaN      NaN   \n",
       "2  9000099      NaN      NaN      NaN      1.0  53700.0      NaN      NaN   \n",
       "3  9000099      NaN      NaN      NaN      1.0  29700.0      NaN      NaN   \n",
       "4  9000099      NaN      NaN      NaN      1.0  27600.0      NaN      NaN   \n",
       "\n",
       "   VCOLL2  ILLPWK1   ...     ACT37A  ACT37B  ACT37C  ACT37D  ACTNAA  ACTNAB  \\\n",
       "0     NaN      0.0   ...        NaN     NaN     NaN     NaN     NaN     NaN   \n",
       "1     NaN      0.0   ...        NaN     NaN     NaN     NaN     NaN     NaN   \n",
       "2     NaN      0.0   ...        NaN     NaN     NaN     NaN     NaN     NaN   \n",
       "3     NaN      0.0   ...        NaN     NaN     NaN     NaN     NaN     NaN   \n",
       "4     NaN      0.0   ...        NaN     NaN     NaN     NaN     NaN     NaN   \n",
       "\n",
       "   ACTNAC  ACTNAD  prior_visit       id  \n",
       "0     NaN     NaN         10.0  9000099  \n",
       "1     NaN     NaN         10.0  9000099  \n",
       "2     NaN     NaN         10.0  9000099  \n",
       "3     NaN     NaN         10.0  9000099  \n",
       "4     NaN     NaN         10.0  9000099  \n",
       "\n",
       "[5 rows x 1426 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# getting information about the last contact prior to replacement...\n",
    "visit_to_keep = -1\n",
    "if visit_to_keep != -1:\n",
    "    DT_outcome['prior_visit'] = visit_to_keep\n",
    "else:\n",
    "    DT_outcome['prior_visit'] = DT_outcome[tVSPR].max(axis=1).fillna(10) # Last visit prior to replacement...\n",
    "\n",
    "\n",
    "ALLDATA_VISITS = ALLDATA.merge(DT_outcome[['prior_visit','id']],left_on='ID', right_on='id', how='outer')\n",
    "ALLDATA_VISITS.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_before = True  # 'True' keeps all visits before visit_to_keep, 'False' keeps only visit_to_keep\n",
    "if all_before:\n",
    "    ALLDATA_VISITS = ALLDATA_VISITS[ALLDATA_VISITS['prior_visit'] >= ALLDATA_VISITS['visit']]\n",
    "else:\n",
    "    # keeping information of only the last visit\n",
    "    ALLDATA_VISITS = ALLDATA_VISITS[ALLDATA_VISITS['prior_visit'] == ALLDATA_VISITS['visit']]\n",
    "    \n",
    "ALLDATA_VISITS['lifetime_visits'] = np.abs(ALLDATA_VISITS['prior_visit'] - ALLDATA_VISITS['visit'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   visit  prior_visit  lifetime_visits       id\n",
      "0      0         10.0             10.0  9000099\n",
      "1      2         10.0              8.0  9000099\n",
      "2      3         10.0              7.0  9000099\n",
      "3      4         10.0              6.0  9000099\n",
      "4      5         10.0              5.0  9000099\n"
     ]
    }
   ],
   "source": [
    "print(ALLDATA_VISITS[['visit', 'prior_visit','lifetime_visits','id']].head())\n",
    "ALLDATA_VISITS = ALLDATA_VISITS.drop(['id','visit','prior_visit'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#######\n",
    "# Considering to drop the columns below\n",
    "\n",
    "tSREPHR = [i for i in ALLDATA_VISITS.columns if i[0:4] =='SREP']   # Ever have replacement surgery where all or part of joint was replaced, self-report\n",
    "tPSDATE = [i for i in ALLDATA_VISITS.columns if i =='PSDATE']   # Date MRI Safety Screener completed\n",
    "tSSDATE = [i for i in ALLDATA_VISITS.columns if i =='SSDATE']   # \n",
    "tObjects = list(ALLDATA_VISITS.dtypes[ALLDATA_VISITS.dtypes == 'object'].keys())\n",
    "\n",
    "to_drop = tSREPHR + tPSDATE + tSSDATE + tObjects\n",
    "\n",
    "\n",
    "ALLDATA_VISITS = ALLDATA_VISITS.drop(to_drop,axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Aggregating all visits by mean, grouped by ID..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ALLDATA_VISITS = ALLDATA_VISITS.groupby('ID', as_index=False).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training and Testing Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import metrics\n",
    "import lightgbm as lgb\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Targets:  ['V99ERKRPCF', 'V99ELKRPCF', 'V99ERHRPCF', 'V99ELHRPCF']\n",
      "Dataset:  (40903, 1397)\n",
      "Train dataset: (40903, 1396)\n"
     ]
    }
   ],
   "source": [
    "target_name = tRPCF  # choosing replacement adjucation features\n",
    "\n",
    "# merging targets with jointsx dataset\n",
    "X = ALLDATA_VISITS.merge(DT_outcome[target_name + ['id']], left_on='ID', right_on='id', how='outer')\n",
    "\n",
    "ids = X['ID']\n",
    "TARGETS = X[target_name]\n",
    "\n",
    "X = X.drop(['ID','id'] + target_name,axis=1)\n",
    "train = X.fillna(-1)\n",
    "train = pd.get_dummies(train)\n",
    "\n",
    "train_target = TARGETS.sum(axis=1)   ## summing all the replacements\n",
    "train_target = train_target.fillna(0)     # if no information, then 0\n",
    "train_target[train_target >= 1] = 1       # if greater than 0... at least one replacement occurred\n",
    "print('Targets: ', target_name)\n",
    "print('Dataset: ', ALLDATA_VISITS.shape)\n",
    "print('Train dataset:', train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Measuring feature importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================== \n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[200]\tvalid_0's auc: 0.951414\n",
      "[400]\tvalid_0's auc: 0.952643\n",
      "Early stopping, best iteration is:\n",
      "[319]\tvalid_0's auc: 0.953281\n",
      "\n",
      "===========================================================\n",
      "Model \n",
      "TN 9240 , FN 292 , FP 85 , TP 609\n",
      "AUC =  0.833400183889\n",
      "Acc: 0.963133189908\n",
      "==============\n",
      "\n",
      "0 Frequency:  0.911891257579\n",
      "\n",
      "==================================\n",
      "BASELINE\n",
      "TN 9325 , FN 901 , FP 0 , TP 0\n",
      "AUC =  0.5\n",
      "Acc: 0.911891257579\n",
      "======================================================================== \n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[200]\tvalid_0's auc: 0.953222\n",
      "Early stopping, best iteration is:\n",
      "[234]\tvalid_0's auc: 0.953946\n",
      "\n",
      "===========================================================\n",
      "Model \n",
      "TN 9169 , FN 360 , FP 82 , TP 615\n",
      "AUC =  0.810952662082\n",
      "Acc: 0.956776843341\n",
      "==============\n",
      "\n",
      "0 Frequency:  0.904654801486\n",
      "\n",
      "==================================\n",
      "BASELINE\n",
      "TN 9251 , FN 975 , FP 0 , TP 0\n",
      "AUC =  0.5\n",
      "Acc: 0.904654801486\n",
      "======================================================================== \n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[200]\tvalid_0's auc: 0.949856\n",
      "Early stopping, best iteration is:\n",
      "[158]\tvalid_0's auc: 0.950249\n",
      "\n",
      "===========================================================\n",
      "Model \n",
      "TN 9250 , FN 336 , FP 72 , TP 568\n",
      "AUC =  0.810297459811\n",
      "Acc: 0.960101701545\n",
      "==============\n",
      "\n",
      "0 Frequency:  0.911597887737\n",
      "\n",
      "==================================\n",
      "BASELINE\n",
      "TN 9322 , FN 904 , FP 0 , TP 0\n",
      "AUC =  0.5\n",
      "Acc: 0.911597887737\n",
      "======================================================================== \n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[200]\tvalid_0's auc: 0.951609\n",
      "Early stopping, best iteration is:\n",
      "[250]\tvalid_0's auc: 0.952515\n",
      "\n",
      "===========================================================\n",
      "Model \n",
      "TN 9259 , FN 334 , FP 84 , TP 549\n",
      "AUC =  0.806376683072\n",
      "Acc: 0.959123802073\n",
      "==============\n",
      "\n",
      "0 Frequency:  0.913651476628\n",
      "\n",
      "==================================\n",
      "BASELINE\n",
      "TN 9343 , FN 883 , FP 0 , TP 0\n",
      "AUC =  0.5\n",
      "Acc: 0.913651476628\n",
      "======================================================================== \n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[200]\tvalid_0's auc: 0.954448\n",
      "[400]\tvalid_0's auc: 0.954409\n",
      "Early stopping, best iteration is:\n",
      "[327]\tvalid_0's auc: 0.955448\n",
      "\n",
      "===========================================================\n",
      "Model \n",
      "TN 9254 , FN 315 , FP 101 , TP 556\n",
      "AUC =  0.81377518116\n",
      "Acc: 0.959319381968\n",
      "==============\n",
      "\n",
      "0 Frequency:  0.914824955995\n",
      "\n",
      "==================================\n",
      "BASELINE\n",
      "TN 9355 , FN 871 , FP 0 , TP 0\n",
      "AUC =  0.5\n",
      "Acc: 0.914824955995\n"
     ]
    }
   ],
   "source": [
    "# Create the model with several hyperparameters\n",
    "model = lgb.LGBMClassifier(objective='binary', boosting_type = 'gbdt', n_estimators = 10000)#, class_weight={0:0.3,1:0.7})\n",
    "\n",
    "# Initialize an empty array to hold feature importances\n",
    "feature_importances = np.zeros(train.shape[1])\n",
    "\n",
    "iterations = 5\n",
    "# Fit the model twice to avoid overfitting\n",
    "for i in range(iterations):\n",
    "    \n",
    "    # Split into training and validation set\n",
    "    train_features, valid_features, train_y, valid_y = train_test_split(train, train_target, test_size = 0.25, random_state = i)\n",
    "\n",
    "    print('======================================================================== ')        \n",
    "    # Train using early stopping\n",
    "    model.fit(train_features, train_y, early_stopping_rounds=100, \n",
    "              eval_set = [(valid_features, valid_y)], eval_metric = 'auc', verbose = 200)\n",
    "\n",
    "    print('\\n===========================================================\\nModel ')        \n",
    "    valid_pred = model.predict(valid_features, num_iteration=model.best_iteration_)\n",
    "    vmetrics = confusion_matrix(valid_y,valid_pred)\n",
    "    print ('TN',vmetrics[0,0],', FN',vmetrics[1,0],', FP',vmetrics[0,1],', TP',vmetrics[1,1])\n",
    "    fpr, tpr, thresholds = metrics.roc_curve(valid_y, valid_pred)\n",
    "    print('AUC = ', metrics.auc(fpr, tpr))    \n",
    "    print ('Acc:', (vmetrics[0,0] + vmetrics[1,1]) / len(valid_y))\n",
    "    \n",
    "    print('==============')\n",
    "    print('\\n0 Frequency: ', (1 - valid_y.sum()/len(valid_y)))\n",
    "   \n",
    "    print('\\n==================================\\nBASELINE') \n",
    "    valid_pred = np.zeros(len(valid_y))\n",
    "    baseline = confusion_matrix(valid_y,valid_pred)\n",
    "    fpr, tpr, thresholds = metrics.roc_curve(valid_y, valid_pred)\n",
    "    print ('TN',baseline[0,0],', FN',baseline[1,0],', FP',baseline[0,1],', TP',baseline[1,1])\n",
    "    print('AUC = ', metrics.auc(fpr, tpr))\n",
    "    print ('Acc:', (baseline[0,0] + baseline[1,1]) / len(valid_y))\n",
    "    \n",
    "    # Record the feature importances\n",
    "    feature_importances += model.feature_importances_\n",
    "\n",
    "feature_importances /= iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 483 no important features\n"
     ]
    }
   ],
   "source": [
    "feature_importances = pd.DataFrame({'feature': list(train.columns), 'importance': feature_importances}\n",
    "                                  ).sort_values('importance', ascending = False)\n",
    "\n",
    "# Find the features with zero importance\n",
    "least_important = list(feature_importances[feature_importances['importance'] <= 0]['feature'])\n",
    "print('There are %d no important features' % len(least_important))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resulting Training shape:  (40903, 913)\n"
     ]
    }
   ],
   "source": [
    "train = train.drop(columns = least_important)\n",
    "#test = test.drop(columns=least_important)\n",
    "\n",
    "print('Resulting Training shape: ', train.shape)\n",
    "#print('Testing shape: ', test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=========================================================\n",
      "train:  (20451, 913)  test:  (20452, 913)\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[200]\tvalid_0's auc: 0.944743\n",
      "[400]\tvalid_0's auc: 0.947752\n",
      "Early stopping, best iteration is:\n",
      "[342]\tvalid_0's auc: 0.949942\n",
      "\n",
      "==== Testing best iteration ====\n",
      "TN 18511 , FN 716 , FP 155 , TP 1070\n",
      "AUC =  0.795400137671\n",
      "Acc: 0.957412477997\n",
      "\n",
      "=========================================================\n",
      "train:  (20451, 913)  test:  (20452, 913)\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[200]\tvalid_0's auc: 0.95578\n",
      "Early stopping, best iteration is:\n",
      "[276]\tvalid_0's auc: 0.957646\n",
      "\n",
      "==== Testing best iteration ====\n",
      "TN 18492 , FN 721 , FP 170 , TP 1069\n",
      "AUC =  0.794048641849\n",
      "Acc: 0.956434578525\n",
      "\n",
      "=========================================================\n",
      "train:  (20451, 913)  test:  (20452, 913)\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[200]\tvalid_0's auc: 0.950976\n",
      "[400]\tvalid_0's auc: 0.953492\n",
      "Early stopping, best iteration is:\n",
      "[348]\tvalid_0's auc: 0.954849\n",
      "\n",
      "==== Testing best iteration ====\n",
      "TN 18482 , FN 733 , FP 165 , TP 1072\n",
      "AUC =  0.79252860441\n",
      "Acc: 0.95609231371\n",
      "\n",
      "=========================================================\n",
      "train:  (20451, 913)  test:  (20452, 913)\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[200]\tvalid_0's auc: 0.949514\n",
      "Early stopping, best iteration is:\n",
      "[294]\tvalid_0's auc: 0.954332\n",
      "\n",
      "==== Testing best iteration ====\n",
      "TN 18458 , FN 697 , FP 185 , TP 1112\n",
      "AUC =  0.802390480444\n",
      "Acc: 0.956874633288\n",
      "\n",
      "=========================================================\n",
      "train:  (20451, 913)  test:  (20452, 913)\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[200]\tvalid_0's auc: 0.946753\n",
      "[400]\tvalid_0's auc: 0.94994\n",
      "Early stopping, best iteration is:\n",
      "[483]\tvalid_0's auc: 0.950615\n",
      "\n",
      "==== Testing best iteration ====\n",
      "TN 18453 , FN 721 , FP 183 , TP 1095\n",
      "AUC =  0.796576932241\n",
      "Acc: 0.955798943869\n",
      "\n",
      "=========================================================\n",
      "train:  (20451, 913)  test:  (20452, 913)\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[200]\tvalid_0's auc: 0.950697\n",
      "[400]\tvalid_0's auc: 0.955345\n",
      "Early stopping, best iteration is:\n",
      "[373]\tvalid_0's auc: 0.955806\n",
      "\n",
      "==== Testing best iteration ====\n",
      "TN 18482 , FN 704 , FP 159 , TP 1107\n",
      "AUC =  0.801367454716\n",
      "Acc: 0.957803637786\n",
      "\n",
      "=========================================================\n",
      "train:  (20451, 913)  test:  (20452, 913)\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[200]\tvalid_0's auc: 0.942278\n",
      "[400]\tvalid_0's auc: 0.94442\n",
      "Early stopping, best iteration is:\n",
      "[335]\tvalid_0's auc: 0.945103\n",
      "\n",
      "==== Testing best iteration ====\n",
      "TN 18467 , FN 756 , FP 171 , TP 1058\n",
      "AUC =  0.787033325592\n",
      "Acc: 0.954674359476\n",
      "\n",
      "=========================================================\n",
      "train:  (20451, 913)  test:  (20452, 913)\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[200]\tvalid_0's auc: 0.937189\n",
      "[400]\tvalid_0's auc: 0.939995\n",
      "Early stopping, best iteration is:\n",
      "[337]\tvalid_0's auc: 0.94114\n",
      "\n",
      "==== Testing best iteration ====\n",
      "TN 18479 , FN 718 , FP 173 , TP 1082\n",
      "AUC =  0.795917983177\n",
      "Acc: 0.956434578525\n",
      "\n",
      "=========================================================\n",
      "train:  (20451, 913)  test:  (20452, 913)\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[200]\tvalid_0's auc: 0.943685\n",
      "[400]\tvalid_0's auc: 0.952396\n",
      "Early stopping, best iteration is:\n",
      "[441]\tvalid_0's auc: 0.952935\n",
      "\n",
      "==== Testing best iteration ====\n",
      "TN 18492 , FN 735 , FP 161 , TP 1064\n",
      "AUC =  0.791404184679\n",
      "Acc: 0.956190103657\n",
      "\n",
      "=========================================================\n",
      "train:  (20451, 913)  test:  (20452, 913)\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[200]\tvalid_0's auc: 0.947284\n",
      "Early stopping, best iteration is:\n",
      "[240]\tvalid_0's auc: 0.948946\n",
      "\n",
      "==== Testing best iteration ====\n",
      "TN 18467 , FN 747 , FP 173 , TP 1065\n",
      "AUC =  0.789233614246\n",
      "Acc: 0.955016624291\n"
     ]
    }
   ],
   "source": [
    "Testing = False\n",
    "\n",
    "iterations = 10\n",
    "# Fit the model twice to avoid overfitting\n",
    "for i in range(iterations):\n",
    "\n",
    "    if not Testing:\n",
    "        model = lgb.LGBMClassifier(objective='binary', boosting_type = 'dart', n_estimators = 10000)#, class_weight={0:0.3,1:0.7})    \n",
    "    \n",
    "    print('\\n=========================================================')\n",
    "    # splitting test and train dataset...\n",
    "    train_features, test_features, train_target_, test_target_ = train_test_split(train, train_target, test_size = 0.5, random_state = i)\n",
    "    print('train: ', train_features.shape, ' test: ' ,test_features.shape)\n",
    "    \n",
    "    # splitting validation and train dataset...\n",
    "    train_X, valid_X, train_y, valid_y = train_test_split(train_features, train_target_, test_size = 0.25, random_state = i)\n",
    "    \n",
    "    if not Testing:\n",
    "        model.fit(train_X, train_y, early_stopping_rounds=100, eval_set = [(valid_X, valid_y)], eval_metric = 'auc', verbose = 200)\n",
    "\n",
    "\n",
    "    print('\\n==== Testing best iteration ====')\n",
    "    test_pred = model.predict(test_features, num_iteration=model.best_iteration_)\n",
    "\n",
    "        \n",
    "    vmetrics = confusion_matrix(test_target_,test_pred)\n",
    "    print ('TN',vmetrics[0,0],', FN',vmetrics[1,0],', FP',vmetrics[0,1],', TP',vmetrics[1,1])\n",
    "    fpr, tpr, thresholds = metrics.roc_curve(test_target_, test_pred)\n",
    "    print('AUC = ', metrics.auc(fpr, tpr))    \n",
    "    print ('Acc:', (vmetrics[0,0] + vmetrics[1,1]) / len(test_target_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
